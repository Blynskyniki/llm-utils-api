# LLM Service API

LLM Service API — это приложение на Node.js, написанное на TypeScript, которое предоставляет унифицированный интерфейс для взаимодействия с большими языковыми моделями (LLM), как локальными, так и через внешние API, такие как OpenAI. Сервис спроектирован таким образом, чтобы быть гибким и расширяемым, позволяя легко переключаться между различными провайдерами LLM.

## Содержание

- [Особенности](#особенности)
- [Предварительные требования](#предварительные-требования)
- [Установка](#установка)
- [Конфигурация](#конфигурация)
- [Запуск проекта](#запуск-проекта)
- [Документация API](#документация-api)
- [Структура проекта](#структура-проекта)
- [Использование](#использование)
    - [Аутентификация](#аутентификация)
    - [Эндпоинты](#эндпоинты)



## Особенности

- **Унифицированный интерфейс**: Абстрагирует взаимодействие с различными LLM через интерфейсы провайдеров.
- **Множественные провайдеры**: Поддерживает как локальные модели, так и внешние API (например, OpenAI).
- **Расширяемая архитектура**: Легко добавляйте новых провайдеров или функциональности с помощью фабричных классов.
- **Функциональность**:
    - Эмбеддинги текста и изображений
    - Транскрибация
    - Суммаризация
    - Чат с использованием RAG (Retrieval-Augmented Generation)
    - Генерация изображений
- **Поддержка стриминга**: Возможность получать ответы в режиме стриминга (`stream: true/false`).
- **Сервер API на Fastify**: Построен на Fastify, обеспечивая высокую производительность.
- **Аутентификация**: Базовая аутентификация с использованием учетных данных из переменных окружения.
- **Swagger UI**: Интегрированная документация API через Swagger UI.
- **Поддержка CORS**: Настроен для разрешения кросс-доменных запросов.

## Предварительные требования

- **Node.js**: Версия 14 или выше
- **npm**: Версия 6 или выше
- **TypeScript**: Установлен глобально или как dev-зависимость
- **OpenAI API Key**: Необходим, если вы используете OpenAI в качестве провайдера

## Установка

### Клонирование репозитория

```bash
git clone https://github.com/yourusername/llm-service-api.git
cd llm-service-api
```

### Установка зависимостей

```bash
npm install
```

## Конфигурация

Создайте файл `.env` в корневой директории проекта и установите следующие переменные окружения:

```env
USERNAME=your_username
PASSWORD=your_password
OPENAI_API_KEY=your_openai_api_key
PORT=3000
```

- `USERNAME` и `PASSWORD`: Учетные данные для базовой аутентификации.
- `OPENAI_API_KEY`: Ваш API-ключ OpenAI (требуется, если вы используете OpenAI в качестве провайдера).
- `PORT`: Порт, на котором будет работать сервер (по умолчанию 3000).

## Запуск проекта

### Режим разработки

Чтобы запустить проект в режиме разработки с автоматической перезагрузкой при изменении файлов:

```bash
npm run dev
```

### Режим продакшена

Сначала соберите проект:

```bash
npm run build
```

Затем запустите сервер:

```bash
npm start
```

## Документация API

После запуска сервера Swagger UI доступен по адресу:

```
http://localhost:3000/documentation
```

Здесь вы можете изучить эндпоинты API, просмотреть схемы запросов и ответов, а также протестировать API.

## Структура проекта

```
llm-service-api/
├── src/
│   ├── interfaces/
│   │   ├── ChatProvider.ts
│   │   ├── EmbeddingsProvider.ts
│   │   ├── ImageGenerationProvider.ts
│   │   ├── SummarizationProvider.ts
│   │   └── TranscriptionProvider.ts
│   ├── factories/
│   │   └── LLMFactory.ts
│   ├── providers/
│   │   ├── LocalModelProvider.ts
│   │   └── OpenAIProvider.ts
│   ├── routes/
│   │   ├── chat.ts
│   │   ├── embeddings.ts
│   │   ├── generateImage.ts
│   │   ├── summarize.ts
│   │   └── transcribe.ts
│   ├── models/
│   │   └── ChatMessage.ts
│   ├── utils/
│   │   └── authentication.ts
│   ├── server.ts
│   └── index.ts
├── types/
│   └── onnxruntime-node.d.ts
├── .env
├── package.json
├── tsconfig.json
└── README.md
```

- **src/interfaces**: Определения интерфейсов для различных функциональностей.
- **src/factories**: Фабричные классы для создания провайдеров.
- **src/providers**: Реализации провайдеров (например, OpenAIProvider, LocalModelProvider).
- **src/routes**: Обработчики маршрутов API.
- **src/models**: Модели данных (например, ChatMessage).
- **src/utils**: Утилиты (например, аутентификация).
- **types**: Определения типов для сторонних модулей без поддержки TypeScript.

## Использование

### Аутентификация

Все эндпоинты защищены базовой аутентификацией. Включите заголовок `Authorization` в ваши запросы:

```
Authorization: Basic <base64(username:password)>
```

### Эндпоинты

#### 1. Текстовые эмбеддинги

- **Эндпоинт**: `POST /embeddings/text`
- **Описание**: Получить эмбеддинги текста.
- **Параметры тела**:
    - `input` (string): Текстовый ввод.
    - `provider` (string): Используемый провайдер (`OpenAI`, `Local`).
- **Ответ**:
    - `embeddings` (array of numbers): Вектор эмбеддингов.

#### 2. Эмбеддинги изображений

- **Эндпоинт**: `POST /embeddings/image`
- **Описание**: Получить эмбеддинги изображения.
- **Параметры тела**:
    - `image` (binary): Файл изображения.
    - `provider` (string): Используемый провайдер.
- **Ответ**:
    - `embeddings` (array of numbers): Вектор эмбеддингов.

#### 3. Транскрибация

- **Эндпоинт**: `POST /transcribe`
- **Описание**: Транскрибировать аудио.
- **Параметры тела**:
    - `audio` (binary): Аудиофайл.
    - `provider` (string): Используемый провайдер.
    - `options` (object):
        - `stream` (boolean): Стримить ли ответ.
- **Ответ**:
    - `transcription` (string): Транскрибированный текст.

#### 4. Суммаризация

- **Эндпоинт**: `POST /summarize`
- **Описание**: Суммаризировать текст.
- **Параметры тела**:
    - `text` (string): Текст для суммаризации.
    - `provider` (string): Используемый провайдер.
- **Ответ**:
    - `summary` (string): Суммаризированный текст.

#### 5. Чат

- **Эндпоинт**: `POST /chat`
- **Описание**: Общение с LLM в режиме чата.
- **Параметры тела**:
    - `messages` (array of ChatMessage objects): Сообщения беседы.
        - `role` (string): Роль отправителя сообщения (`user`, `assistant`, `system`).
        - `content` (string): Содержимое сообщения.
    - `provider` (string): Используемый провайдер.
    - `options` (object):
        - `stream` (boolean): Стримить ли ответ.
- **Ответ**:
    - `response` (string): Ответ ассистента.

#### 6. Генерация изображений

- **Эндпоинт**: `POST /generate-image`
- **Описание**: Генерация изображения по текстовому описанию.
- **Параметры тела**:
    - `prompt` (string): Текстовый промпт для генерации изображения.
    - `provider` (string): Используемый провайдер.
- **Ответ**:
    - **Content-Type**: `image/png`
    - **Тело**: Сгенерированное изображение в виде бинарных данных.



## Технологии

- [Fastify](https://www.fastify.io/) — веб-фреймворк для Node.js
- [OpenAI](https://openai.com/) — AI-модели и API
- [TypeScript](https://www.typescriptlang.org/) — типизированный JavaScript
- [@xenova/transformers](https://www.npmjs.com/package/@xenova/transformers) — библиотека Transformers для JavaScript
- [Swagger UI](https://swagger.io/tools/swagger-ui/) — инструмент для документации API

---

Если у вас есть вопросы или вам нужна помощь, не стесняйтесь открыть issue или связаться с поддержкой.
